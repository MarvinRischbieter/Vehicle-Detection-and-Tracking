{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Udacity Self-Driving Car Engineer Nanodegree Program\n",
    "\n",
    "## Vehicle Detection and Tracking Project\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import hog\n",
    "from skimage.io import imread\n",
    "from skimage.exposure import adjust_gamma\n",
    "from scipy.misc import imresize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.externals import joblib\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.ndimage.measurements import label\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from moviepy.editor import VideoFileClip\n",
    "%matplotlib inline\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_images_in_table (images, table_size, fig_size = (10, 10), cmap=None, titles=None):\n",
    "    \"\"\"Shows images in table\n",
    "    Args:\n",
    "        images (list): list of input images\n",
    "        table_size (tuple): (cols count, rows count)\n",
    "        fig_size (tuple): picture (size x, size y) in inches\n",
    "        cmap (list): list of cmap parameters for each image\n",
    "        titles (list): list of images titles\n",
    "    \"\"\"\n",
    "    sizex = table_size [0]\n",
    "    sizey = table_size [1]\n",
    "    fig, imtable = plt.subplots (sizey, sizex, figsize = fig_size, squeeze=False)\n",
    "    for j in range (sizey):\n",
    "        for i in range (sizex):\n",
    "            im_idx = i + j*sizex\n",
    "            if (isinstance(cmap, (list, tuple))):\n",
    "                imtable [j][i].imshow (images[im_idx], cmap=cmap[i])\n",
    "            else:\n",
    "                im = images[im_idx]\n",
    "                if len(im.shape) == 3:\n",
    "                    imtable [j][i].imshow (im)\n",
    "                else:\n",
    "                    imtable [j][i].imshow (im, cmap='gray')\n",
    "            imtable [j][i].axis('off')\n",
    "            if not titles is None:\n",
    "                imtable [j][i].set_title (titles [im_idx], fontsize=32)\n",
    "\n",
    "    plt.show ()\n",
    "\n",
    "def plt_show_gray (image):\n",
    "    \"\"\"Shows gray image\n",
    "    Args:\n",
    "        image: image to show\n",
    "    \"\"\"\n",
    "    plt.figure ()\n",
    "    plt.imshow (image, cmap='gray')\n",
    "    plt.show ()\n",
    "\n",
    "def plt_show (image):\n",
    "    \"\"\"Shows color image in RGB format\n",
    "    Args:\n",
    "        image: image to show\n",
    "    \"\"\"\n",
    "    plt.figure ()\n",
    "    plt.imshow (image)\n",
    "    plt.show ()\n",
    "    \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Visualize the Labeled data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "#from skimage.feature import hog\n",
    "#from skimage import color, exposure\n",
    "# images are divided up into vehicles and non-vehicles\n",
    "\n",
    "cars =  glob.glob('data/vehicles/**/*.png') \n",
    "notcars =  glob.glob('data/non-vehicles/**/*.png')\n",
    "\n",
    "\n",
    "        \n",
    "# Define a function to return some characteristics of the dataset \n",
    "def data_look(car_list, notcar_list):\n",
    "    data_dict = {}\n",
    "    # Define a key in data_dict \"n_cars\" and store the number of car images\n",
    "    data_dict[\"n_cars\"] = len(car_list)\n",
    "    # Define a key \"n_notcars\" and store the number of notcar images\n",
    "    data_dict[\"n_notcars\"] = len(notcar_list)\n",
    "    # Read in a test image, either car or notcar\n",
    "    example_img = mpimg.imread(car_list[0])\n",
    "    # Define a key \"image_shape\" and store the test image shape 3-tuple\n",
    "    data_dict[\"image_shape\"] = example_img.shape\n",
    "    # Define a key \"data_type\" and store the data type of the test image.\n",
    "    data_dict[\"data_type\"] = example_img.dtype\n",
    "    # Return data_dict\n",
    "    return data_dict\n",
    "    \n",
    "data_info = data_look(cars, notcars)\n",
    "\n",
    "print('Your function returned a count of', \n",
    "      data_info[\"n_cars\"], ' cars and', \n",
    "      data_info[\"n_notcars\"], ' non-cars')\n",
    "print('of size: ',data_info[\"image_shape\"], ' and data type:', \n",
    "      data_info[\"data_type\"])\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(8,8, figsize=(16, 16))\n",
    "fig.subplots_adjust(hspace = .2, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for i in np.arange(32):\n",
    "    img = cv2.imread(cars[np.random.randint(0,len(cars))])\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title('car', fontsize=10)\n",
    "    axs[i].imshow(img)\n",
    "for i in np.arange(32,64):\n",
    "    img = cv2.imread(notcars[np.random.randint(0,len(notcars))])\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].set_title('nope', fontsize=10)\n",
    "    axs[i].imshow(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drawing Rectangles on images\n",
    "Define a function draw_boxes which will be used later to draw bounding rectangles around identified vehicles in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # make a copy of the image\n",
    "    draw_img = np.copy(img)\n",
    "    # draw each bounding box on your image copy using cv2.rectangle()\n",
    "    for box in bboxes:\n",
    "        cv2.rectangle(draw_img, box[0], box[1], color, thick)\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes = [((810,400),(950,495)),((1045,400),(1270,505))]\n",
    "plt.imshow(draw_boxes(mpimg.imread('test_images/test1.jpg'),bboxes=bboxes));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "image = mpimg.imread('test_images/test1.jpg')\n",
    "\n",
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the RGB channels separately\n",
    "    rhist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    ghist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    bhist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Generating bin centers\n",
    "    bin_edges = rhist[1]\n",
    "    bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((rhist[0], ghist[0], bhist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to compute color histogram features  \n",
    "# Pass the color_space flag as 3-letter all caps string\n",
    "# like 'HSV' or 'LUV' etc.\n",
    "def bin_spatial(img, color_space='RGB', size=(32, 32)):\n",
    "    # Convert image to new color space (if specified)\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)             \n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(feature_image, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "import random\n",
    "        \n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient=9, pix_per_cell=8, cell_per_block=2, channel=0, \n",
    "                        vis=False, feature_vec=True, color_space='YUV'):\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                                  visualise=True, feature_vector=False)\n",
    "        return features, hog_image\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                       visualise=False, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Generate a random index to look at a car image\n",
    "\n",
    "# Read in the image\n",
    "\n",
    "car_img =mpimg.imread(cars[np.random.randint(0,len(cars))])\n",
    "\n",
    "_, car_dst = get_hog_features(car_img[:,:,2], 9, 8, 2, vis=True, feature_vec=True)\n",
    "noncar_img = mpimg.imread(notcars[np.random.randint(0,len(notcars))])\n",
    "\n",
    "_, noncar_dst = get_hog_features(noncar_img[:,:,2], 9, 8, 2, vis=True, feature_vec=True)\n",
    "\n",
    "# Visualize \n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(7,7))\n",
    "f.subplots_adjust(hspace = .4, wspace=.2)\n",
    "ax1.imshow(car_img)\n",
    "ax1.set_title('Car Image', fontsize=16)\n",
    "ax2.imshow(car_dst, cmap='gray')\n",
    "ax2.set_title('Car HOG', fontsize=16)\n",
    "ax3.imshow(noncar_img)\n",
    "ax3.set_title('Non-Car Image', fontsize=16)\n",
    "ax4.imshow(noncar_dst, cmap='gray')\n",
    "ax4.set_title('Non-Car HOG', fontsize=16)\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction and Parameters Estimation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for image in imgs:\n",
    "        file_features = []\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            feature_image = cv2.cvtColor (image, getattr(cv2, 'COLOR_RGB2' + color_space))\n",
    "        else: feature_image = np.copy(image)      \n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if color_space == 'GRAY':\n",
    "                hog_features = get_hog_features(feature_image, orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            elif hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "# parameters of feature extraction\n",
    "\n",
    "color_space = 'YUV' # Can be GRAY, RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell =8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = 'ALL' # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # Spatial binning dimensions\n",
    "hist_bins = 16    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "\n",
    "car_image = []\n",
    "for impath in cars:\n",
    "    car_image.append (mpimg.imread(impath))\n",
    "\n",
    "# loading non car images\n",
    "notcar_image = []\n",
    "for impath in notcars:\n",
    "    notcar_image.append (mpimg.imread(impath))\n",
    "\n",
    "ft=time.time()\n",
    "car_features = extract_features(car_image, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(notcar_image, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "ft2=time.time()\n",
    "print ('features extraction time: ', round(ft2-ft, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Normalization\n",
    "'StandardScaler' was used once all the features were extracted to scale the features to have zero mean and unit variance. Data is then split into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lrc = LogisticRegression(max_iter=10)\n",
    "t=time.time()\n",
    "lrc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(t2-t, 'Seconds to train LRC...')\n",
    "print('Train Accuracy of LRC = ', lrc.score(X_train, y_train))\n",
    "print('Test Accuracy of LRC = ', lrc.score(X_test, y_test))\n",
    "t=time.time()\n",
    "prediction = lrc.predict(X_test[0].reshape(1, -1))\n",
    "t2 = time.time()\n",
    "print(t2-t, 'Seconds to predict with LRC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp=MLPClassifier(random_state=54321)\n",
    "t=time.time()\n",
    "mlp.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(t2-t, 'Seconds to train MLP...')\n",
    "# Check the score of the MLP\n",
    "print('Train Accuracy of MLP = ', mlp.score(X_train, y_train))\n",
    "print('Test Accuracy of MLP = ', mlp.score(X_test, y_test))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "prediction = mlp.predict(X_test[0].reshape(1, -1))\n",
    "t2 = time.time()\n",
    "print(t2-t, 'Seconds to predict with MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree=DecisionTreeClassifier()\n",
    "t=time.time()\n",
    "tree.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(t2-t, 'Seconds to train DecisionTreeClassifier...')\n",
    "# Check the score of the MLP\n",
    "print('Train Accuracy of DecisionTreeClassifier = ', tree.score(X_train, y_train))\n",
    "print('Test Accuracy of DecisionTreeClassifier = ', tree.score(X_test, y_test))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "prediction = tree.predict(X_test[0].reshape(1, -1))\n",
    "t2 = time.time()\n",
    "print(t2-t, 'Seconds to predict with DecisionTreeClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1, max_depth=None, min_samples_split=10, random_state=0)\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train RandomForest...')\n",
    "# Check the score of the RandomForest\n",
    "print('Train Accuracy of RandomForest = ', round(clf.score(X_train, y_train), 4))\n",
    "print('Test Accuracy of RandomForest = ', round(clf.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My RandomForest predicts: ', clf.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with RandomForest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, clf, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YUV)\n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell)-1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell)-1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell)-1 \n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    window_list = []\n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "          \n",
    "            # Get color features\n",
    "            spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "            hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = clf.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "                window_list.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "    return window_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm demonstration on test images\n",
    "\n",
    "test_images = []\n",
    "test_images_titles = []\n",
    "\n",
    "for impath in glob.glob('test_images/test*.jpg'):\n",
    "    image=mpimg.imread(impath)\n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "# Read in a pickle file with bboxes saved\n",
    "# Each item in the \"all_bboxes\" list will contain a \n",
    "# list of boxes for one of the images shown above\n",
    "#box_list = pickle.load( open( \"bbox_pickle.p\", \"rb\" ))\n",
    "    ystart = 400\n",
    "    ystop = 656\n",
    "    scale = 1.5\n",
    "    \n",
    "    box_list = find_cars(image, ystart, ystop, scale, mlp, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "\n",
    "# Add heat to each box in box list\n",
    "    heat = add_heat(heat,box_list)\n",
    "    \n",
    "# Apply threshold to help remove false positives\n",
    "#heat = apply_threshold(heat,1)\n",
    "\n",
    "# Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "# Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "\n",
    "\n",
    "    # hot boxes\n",
    "    #image_with_hot_boxes = np.copy(image)\n",
    "    image_with_hot_boxes = draw_boxes(np.copy(image),bboxes=box_list)\n",
    "    test_images.append (image_with_hot_boxes)\n",
    "    test_images.append (heatmap)\n",
    "    test_images.append (draw_img)\n",
    "    \n",
    "    test_images_titles.extend (['', '', ''])\n",
    "    \n",
    "test_images_titles [0] = 'hot boxes'\n",
    "test_images_titles [1] = 'heat map'\n",
    "test_images_titles [2] = 'average boxes'\n",
    "\n",
    "show_images_in_table (test_images, (3, 6), fig_size=(20, 24), titles=test_images_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Implementation\n",
    "\n",
    "This vehicle detection method is run for each image in the project_video.mp4 file. Since we have more frames of reference, we just need to accumulate hot boxes over number of last frames and then apply same algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# in video I use information from multiple frames to\n",
    "# make average boxes more robust and filter false positives\n",
    "# I accumulate all hot boxes from last several frames and use them\n",
    "# for calculating average boxes\n",
    "\n",
    "class LastHotBoxesQueue ():\n",
    "    \"\"\"Class for accumulation of hot boxes from last 10 frames\n",
    "    \"\"\"\n",
    "    def __init__ (self):\n",
    "        self.queue_max_len = 10 # number items to store\n",
    "        self.last_boxes = []\n",
    "\n",
    "    def put_hot_boxes (self, boxes):\n",
    "        \"\"\"Put frame hot boxes\n",
    "        \"\"\"\n",
    "        if (len(self.last_boxes) > self.queue_max_len):\n",
    "            tmp = self.last_boxes.pop (0)\n",
    "        \n",
    "        self.last_boxes.append (boxes)\n",
    "        \n",
    "    def get_hot_boxes (self):\n",
    "        \"\"\"Get last 10 frames hot boxes\n",
    "        \"\"\"\n",
    "        b = []\n",
    "        for boxes in self.last_boxes:\n",
    "            b.extend (boxes)\n",
    "        return b\n",
    "\n",
    "last_hot_boxes = LastHotBoxesQueue ()\n",
    "    \n",
    "def process_image (image_orig):\n",
    "    \n",
    "    image=image_orig\n",
    "    heat = np.zeros_like(image[:,:,0])\n",
    "# Read in a pickle file with bboxes saved\n",
    "# Each item in the \"all_bboxes\" list will contain a \n",
    "# list of boxes for one of the images shown above\n",
    "#box_list = pickle.load( open( \"bbox_pickle.p\", \"rb\" ))\n",
    "    ystart = 400\n",
    "    ystop = 656\n",
    "    scale = 1.5\n",
    "    clf=mlp\n",
    "    box_list = find_cars(image, ystart, ystop, scale, clf, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, hist_bins)\n",
    "    last_hot_boxes.put_hot_boxes (box_list)\n",
    "    box_list = last_hot_boxes.get_hot_boxes ()\n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat,box_list)\n",
    "    \n",
    "# Apply threshold to help remove false positives\n",
    "#heat = apply_threshold(heat,1)\n",
    "\n",
    "# Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "# Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "# Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "\n",
    "    return draw_img \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "# import imageio\n",
    "# imageio.plugins.ffmpeg.download()\n",
    "\n",
    "def process_video (input_path, output_path):\n",
    "    clip = VideoFileClip (input_path)\n",
    "    \n",
    "    # uncomment to operate on individual frames\n",
    "#     image = clip.get_frame(8./30)\n",
    "#     r = process_image(image)\n",
    "#     plt_show (r/255)\n",
    "\n",
    "    result = clip.fl_image (process_image)\n",
    "    %time result.write_videofile (output_path)\n",
    "\n",
    "# select video to operate on\n",
    "#process_video ('test_video.mp4', 'test_video_result.mp4')\n",
    "process_video ('project_video.mp4', 'project_video_result.mp4')\n",
    "# process_video ('challenge_video.mp4', 'challenge_video_result.mp4')\n",
    "# process_video ('harder_challenge_video.mp4', 'harder_challenge_video_result.mp4')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
